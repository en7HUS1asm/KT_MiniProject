{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLojLUpcGNbk"
      },
      "source": [
        "# **차량 공유업체의 차량 파손 여부 분류하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.미션\n",
        "\n",
        "* 1) 미션1 : Data Preprocessing\n",
        "    - **과제 수행 목표**\n",
        "        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n",
        "        - 제공된 데이터 : Car_Images.zip\n",
        "            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"
      ],
      "metadata": {
        "id": "BbrllJY8JdkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2) 미션2 : CNN 모델링\n",
        "    - **과제 수행 목표**\n",
        "        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n",
        "            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n",
        "            - 단, 세부 목차에서 명시한 부분은 지켜주세요."
      ],
      "metadata": {
        "id": "Hgdg96jE-mmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3) 미션3 : Data Argumentation & Transfer Learning\n",
        "    - **과제 수행 목표**\n",
        "        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n",
        "            * Data Augmentation을 적용하세요.(Image Generator)\n",
        "            * Transfer Learning(VGG16)\n"
      ],
      "metadata": {
        "id": "VRrUY4ud_rJV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MdjZtxfGNKz"
      },
      "source": [
        "## 1.환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QgFWzN9xhlr"
      },
      "source": [
        "### (1) 데이터셋 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - C드라이브에 Datasets라는 폴더를 만드세요.\n",
        "        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n",
        "    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 구글 Colab을 이용하는 경우"
      ],
      "metadata": {
        "id": "Elg8NL8vwUs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kWUbDvBzwiTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fb770c-564c-43b9-dcc4-1e41e9e6dd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVNbCKnLUGc"
      },
      "source": [
        "### (2) 데이터셋 불러오기\n",
        "- **세부요구사항**\n",
        "    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n",
        "    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n",
        "        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 폴더구조(로컬)\n",
        "        * C:/Datasets/ : 압축파일\n",
        "        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 폴더구조(구글드라이브브)\n",
        "        * /content/drive/MyDrive/Datasets/ : 압축파일\n",
        "        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n",
        "        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n",
        "        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2-8EaA9x4Xm"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMkstFLKx4Xm"
      },
      "outputs": [],
      "source": [
        "# 압축파일 경로\n",
        "# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n",
        "dataset_path  = '/content/drive/MyDrive/Datasets/'\n",
        "# dataset_path = 'C:/Datasets/'\n",
        "\n",
        "file_path = dataset_path + 'Car_Images.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgT_RB14Lwza"
      },
      "outputs": [],
      "source": [
        "# 압축 해제\n",
        "data = zipfile.ZipFile(file_path)\n",
        "data.extractall('/content/drive/MyDrive/Datasets/Car_Images_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hgC0axQyMhI"
      },
      "source": [
        "### (3) 이미지 저장을 위한 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n",
        "        - train\n",
        "            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/\n",
        "                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n",
        "            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n",
        "                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n",
        "        - val, test 역시 동일한 구조로 생성합니다.\n",
        "    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n",
        "        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc8GnuauOzLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "e3f92826-ed0b-40ed-c722-9645b8af1641"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-ab18be818708>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_train/normal\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 각각 경로 지정\n",
        " os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_train/normal\")\n",
        " os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_train/abnormal\")\n",
        "\n",
        "# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n",
        "\n",
        "# test 폴더 만들기 os.mkdir()\n",
        "# os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_test\")\n",
        "# os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_test/normal\")\n",
        "# os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_test/abnormal\")\n",
        "\n",
        "\n",
        "# validation 폴더 만들기\n",
        "try:\n",
        "  os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_val\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_val/normal\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/Datasets/Car_Images_val/abnormal\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# try, except\n",
        "# try:            # 실행하고싶은코드\n",
        "#  ~~~\n",
        "# except:         # try에서 오류가 났을 경우 대신 실행할 코드\n",
        "#   pass -->오류뜨면 넘어감."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZKJrP0GtPh"
      },
      "source": [
        "## 2.데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ilpDQfInAE"
      },
      "source": [
        "### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n",
        "- **세부요구사항**\n",
        "    - Training set, Validation set, Test set을 만듭니다.\n",
        "        * size\n",
        "            * test : 전체에서 20%를 추출합니다.\n",
        "            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n",
        "        * 데이터는 랜덤하게 추출해야 합니다.\n",
        "            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n",
        "                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) test, validation 크기를 지정"
      ],
      "metadata": {
        "id": "mFMSDA26RS-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQ_Gu_KNR2g"
      },
      "outputs": [],
      "source": [
        "import random, shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_n_path = '/content/drive/MyDrive/Datasets/Car_Images_train/normal'\n",
        "tr_ab_path = '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'"
      ],
      "metadata": {
        "id": "O02HSppEwiik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdU7X9e70dBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9928f76b-e57f-47d8-84e0-f09bd0cbf885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194, 194)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 전체 이미지 갯수를 확인합니다.\n",
        "len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa2mxylBDVM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2fde44-f346-4eb1-b07b-4a74ec8a50e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[60, 61]\n",
            "[48, 48]\n"
          ]
        }
      ],
      "source": [
        "# test 사이즈 : 전체 이미지의 20%\n",
        "te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n",
        "print(te_data_num)\n",
        "\n",
        "# validation 사이즈 : test를 제외한 나머지 중에서 20%\n",
        "val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_n_path))-te_data_num[1])*0.2) ]\n",
        "print(val_data_num)\n",
        "\n",
        "# train 사이즈\n",
        "train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0],\n",
        "                  len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # os.listdir(tr_n_path)[0]\n",
        "os.listdir(tr_n_path)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jlLmM6kTXcDT",
        "outputId": "1731bf24-9bce-48fd-99cf-09ebe063a2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DALLíñE 2023-03-10 18.50.29 - photo of a part of car.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) test 셋 추출"
      ],
      "metadata": {
        "id": "RmRhrViWRXgL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSwovHr2Fon1"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "\n",
        "normal_images = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/normal')\n",
        "abnormal_images = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal')\n",
        "\n",
        "for i in range (te_data_num[0]):\n",
        " shutil.move('/content/drive/MyDrive/Datasets/Car_Images_train/normal/'+os.listdir(tr_n_path)[i],'/content/drive/MyDrive/Datasets/Car_Images_test/normal' )\n",
        "\n",
        "for i in range (te_data_num[1]):\n",
        " shutil.move('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal/'+os.listdir(tr_ab_path)[i],'/content/drive/MyDrive/Datasets/Car_Images_test/abnormal' )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_n_path = '/content/drive/MyDrive/Datasets/Car_Images_train/normal'\n",
        "train_ab_path = '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'\n",
        "val_n_path = '/content/drive/MyDrive/Datasets/Car_Images_val/normal'\n",
        "val_ab_path = '/content/drive/MyDrive/Datasets/Car_Images_val/abnormal'\n",
        "test_n_path = '/content/drive/MyDrive/Datasets/Car_Images_test/normal'\n",
        "test_ab_path = '/content/drive/MyDrive/Datasets/Car_Images_test/abnormal'"
      ],
      "metadata": {
        "id": "pS7NK7LOD2n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AImO1ujiI2IY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f5c259-4462-43a9-bdb2-304066b79aa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "\n",
        "# len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/normal'))\n",
        "# len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal'))\n",
        "# len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) validation 셋 추출"
      ],
      "metadata": {
        "id": "2V4mh3hxRpR2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXYmEdCjAEDu"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "\n",
        "normal_images = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/normal')\n",
        "abnormal_images = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal')\n",
        "\n",
        "for i in range (val_data_num[0]):\n",
        " shutil.move('/content/drive/MyDrive/Datasets/Car_Images_train/normal/'+os.listdir(tr_n_path)[i],'/content/drive/MyDrive/Datasets/Car_Images_val/normal' )\n",
        "\n",
        "for i in range (val_data_num[1]):\n",
        " shutil.move('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal/'+os.listdir(tr_ab_path)[i],'/content/drive/MyDrive/Datasets/Car_Images_val/abnormal' )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIT85iSdM4U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b83ea0-71c0-47c1-f04e-5ba48d2c45e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "\n",
        "len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_val/normal'))\n",
        "#len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_val/abnormal'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(dataset_path+'Car_Images_test/normal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_test/abnormal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_train/normal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_train/abnormal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_val/normal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_val/abnormal')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-LkxYY_0nPA",
        "outputId": "58abb02f-a4ee-4f12-f6ef-7b1334875628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "61\n",
            "194\n",
            "194\n",
            "48\n",
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSO004sgyyu"
      },
      "source": [
        "### (2) 데이터 복사 및 이동\n",
        "- **세부요구사항**\n",
        "    - 분할된 데이터를 복사 이동합니다.\n",
        "        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n",
        "        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n",
        "    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n",
        "        - 새로운 폴더 명\n",
        "            * copy_images/trainset\n",
        "            * copy_images/validset\n",
        "            * copy_images/testset\n",
        "        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다.\n",
        "            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n",
        "        - os, shutil 모듈을 활용하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) abnormal 파일 복사"
      ],
      "metadata": {
        "id": "3UbNfTY4kOSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 복사하기 : shutil.copytree()"
      ],
      "metadata": {
        "id": "zhkKqLfTkjGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTMVxJJJya98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "17fe4b91-cc94-4018-f585-d3bc2905bbd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Datasets/copy_images/testset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal', '/content/drive/MyDrive/Datasets/copy_images/trainset' )\n",
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_val/abnormal', '/content/drive/MyDrive/Datasets/copy_images/validset' )\n",
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal', '/content/drive/MyDrive/Datasets/copy_images/testset' )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(dataset_path+'Car_Images_train/abnormal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_val/abnormal')))\n",
        "print(len(os.listdir(dataset_path+'Car_Images_test/abnormal')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/trainset')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/validset')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/testset')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llYyMdf9Hkbl",
        "outputId": "b44fcfce-4229-4786-c557-d2598d85f59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194\n",
            "48\n",
            "61\n",
            "383\n",
            "96\n",
            "121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"
      ],
      "metadata": {
        "id": "mU0T-ypHkV6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_train_path='/content/drive/MyDrive/Datasets/copy_images/trainset/'\n",
        "copy_val_path='/content/drive/MyDrive/Datasets/copy_images/validset/'\n",
        "copy_test_path='/content/drive/MyDrive/Datasets/copy_images/testset/'"
      ],
      "metadata": {
        "id": "2Mgm65gdSoyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(copy_train_path):\n",
        "  rename='ab_'+filename\n",
        "  os.rename( copy_train_path+filename, copy_train_path+rename)\n",
        "  filename=rename\n",
        "for filename in os.listdir(copy_val_path):\n",
        "  rename='ab_'+filename\n",
        "  os.rename( copy_val_path+filename, copy_val_path+rename)\n",
        "  filename=rename\n",
        "for filename in os.listdir(copy_test_path):\n",
        "  rename='ab_'+filename\n",
        "  os.rename( copy_test_path+filename, copy_test_path+rename)\n",
        "  filename=rename"
      ],
      "metadata": {
        "id": "IdpX3lotmgr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) normal 파일 복사"
      ],
      "metadata": {
        "id": "Nk6xITmTksyK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw3DmdTS17RM"
      },
      "outputs": [],
      "source": [
        "from distutils.dir_util import copy_tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_train/normal', copy_train_path)\n",
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_val/normal', copy_val_path)\n",
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_test/normal', copy_test_path)"
      ],
      "metadata": {
        "id": "9dNUu_OZUfyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 갯수 조회"
      ],
      "metadata": {
        "id": "xzEXHZrqkz88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugNprP9d-Gti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135d27a8-7980-45a9-e84d-e755c96ab5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383\n",
            "96\n",
            "121\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(dataset_path+'copy_images/trainset/')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/validset/')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/testset/')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYDW1Pj7ZdU"
      },
      "source": [
        "## 3.모델링 I\n",
        "* **세부요구사항**\n",
        "    * 모델링을 위한 데이터 구조 만들기\n",
        "        * x : 이미지를 array로 변환합니다.\n",
        "        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n",
        "    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n",
        "        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n",
        "        * Early Stopping을 반드시 사용하세요.\n",
        "            * 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg553KIvxE6W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIfqg6e0xE6A"
      },
      "source": [
        "### (1) X : image to array\n",
        "- **세부요구사항**\n",
        "    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n",
        "    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다.\n",
        "    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n",
        "        * 각 폴더로 부터 이미지 목록을 만들고\n",
        "        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n",
        "            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n",
        "            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n",
        "            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n",
        "        * 데이터셋에 추가합니다.(데이터셋도 array)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 이미지 목록 만들기\n",
        "* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."
      ],
      "metadata": {
        "id": "FovkIeSDT367"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X022f0QMxE6W"
      },
      "outputs": [],
      "source": [
        "# 이미지 목록 저장\n",
        "img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n",
        "img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n",
        "img_test_list = os.listdir(dataset_path+'copy_images/testset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgvW_LQfxE6X"
      },
      "outputs": [],
      "source": [
        "# 메모리, 처리시간을 위해서 이미지 크기 조정\n",
        "img_size = 280 ## 사이즈 조정 가능"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_train_list)\n",
        "#len(img_valid_list)\n",
        "#len(img_test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyzz8PqXqWH9",
        "outputId": "f7a04c34-edaf-40bb-c9a6-4f838f5fa333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "383"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "388+96+121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPhra0r3unqQ",
        "outputId": "8b9701db-6197-4086-83cc-a136d9cf9b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "605"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train_list"
      ],
      "metadata": {
        "id": "eBywylK8w9xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 이미지들을 배열 데이터셋으로 만들기"
      ],
      "metadata": {
        "id": "LSt88mjPV33u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.utils import load_img, img_to_array"
      ],
      "metadata": {
        "id": "5NOLDUA-xa1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhEdBiKfxE6Y"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "x_val=[]\n",
        "x_test=[]\n",
        "train_path = dataset_path+'copy_images/trainset/'\n",
        "val_path = dataset_path + 'copy_images/validset/'\n",
        "test_path = dataset_path + 'copy_images/testset/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train\n",
        "for file in img_train_list:\n",
        "  img_path = train_path + file\n",
        "  img = load_img(img_path, target_size=(280,280))\n",
        "  img_array = img_to_array(img)\n",
        "  x_train.append(img_array)\n",
        "x_train = np.array(x_train)\n",
        "\n",
        "# x_val\n",
        "for file in img_valid_list:\n",
        "  img_path = val_path + file\n",
        "  img = load_img(img_path, target_size=(280,280))\n",
        "  img_array = img_to_array(img)\n",
        "  x_val.append(img_array)\n",
        "x_val = np.array(x_val)\n",
        "\n",
        "# x_test\n",
        "for file in img_test_list:\n",
        "  img_path = test_path + file\n",
        "  img = load_img(img_path, target_size=(280,280))\n",
        "  img_array = img_to_array(img)\n",
        "  x_test.append(img_array)\n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "NVkRCp3c8nrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train은',x_train.shape)\n",
        "print('x_val은',x_val.shape)\n",
        "print('x_test은',x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saIarBc7EA7P",
        "outputId": "55963d93-c7a6-4e07-e580-0eff570fab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train은 (383, 280, 280, 3)\n",
            "x_val은 (96, 280, 280, 3)\n",
            "x_test은 (121, 280, 280, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whZXKowVyXTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUM37LxxE6Z"
      },
      "source": [
        "### (2) y : 클래스 만들기\n",
        "- **세부요구사항**\n",
        "    - Training set / Validation set / Test set의 y를 생성합니다.\n",
        "        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n",
        "        - normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nl1Uv9UxE6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902f55e5-0b45-48ec-d552-87272353ce2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383\n",
            "194\n",
            "---\n",
            "96\n",
            "48\n",
            "---\n",
            "121\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "# 데이터 갯수 확인\n",
        "print( len(img_train_list) )\n",
        "print( len([val for val in img_train_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_valid_list) )\n",
        "print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_test_list) )\n",
        "print( len([val for val in img_test_list if val.startswith('ab_')]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* y_train, y_valid, y_test 만들기\n",
        "    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."
      ],
      "metadata": {
        "id": "HIfaCLlNn04C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVrPQdhTxE6b"
      },
      "outputs": [],
      "source": [
        "y_train=[]\n",
        "y_val=[]\n",
        "y_test=[]\n",
        "\n",
        "for file in img_train_list:\n",
        " if file.startswith('ab_'):\n",
        "  y_train.append(1)\n",
        " else:\n",
        "  y_train.append(0)\n",
        "\n",
        "for file in img_valid_list:\n",
        " if file.startswith('ab_'):\n",
        "  y_val.append(1)\n",
        " else:\n",
        "  y_val.append(0)\n",
        "\n",
        "for file in img_test_list:\n",
        " if file.startswith('ab_'):\n",
        "  y_test.append(1)\n",
        " else:\n",
        "  y_test.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "2FqaZuXl7kNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1b2fa3-21f5-4932-d15e-c05935102f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfDcWFMDauTl",
        "outputId": "e3d75fc4-91c5-4b13-8704-7ccb7cc1c7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "AeUC6ngVdGXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train=np.expand_dims(y_train, axis=1)\n",
        "# y_val=np.expand_dims(y_val, axis=1)\n",
        "# y_test=np.expand_dims(y_test, axis=1)"
      ],
      "metadata": {
        "id": "jGsSOV2GeKEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train.shape\n",
        "# y_val.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ4kfNSYdGc-",
        "outputId": "ede8cbbc-566f-4008-f4e5-ecdf118a243c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "euPw-AclM7oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. min-max scaling"
      ],
      "metadata": {
        "id": "eMCLm94uemcv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TtIIz6XJQ5E"
      },
      "outputs": [],
      "source": [
        "max_v, min_v = x_train.max(), x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_v, min_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSAoBKCDeveP",
        "outputId": "301ca06f-da60-4cfa-99be-afb0d9f2aaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = (x_train-min_v) / (max_v-min_v)\n",
        "x_val = (x_val-min_v) / (max_v-min_v)\n",
        "x_test = (x_test-min_v) / (max_v-min_v)"
      ],
      "metadata": {
        "id": "gZYdPO_YeviF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.max(), x_val.max(), x_test.max(), x_train.min(), x_val.min(), x_test.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdjT8cw6evkW",
        "outputId": "f1787fc4-a62f-4dcb-f9c4-fbdab355e777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0, 0.0, 0.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot Encoding"
      ],
      "metadata": {
        "id": "ePccyhpGfVn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_n = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "1X7kqG_sfCqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "x6HfJgIufCs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTKZGY1efbCm",
        "outputId": "05c29fba-71dc-43c8-88e5-acdee2eef96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, class_n)\n",
        "y_val = to_categorical(y_val, class_n)\n",
        "y_test = to_categorical(y_test, class_n)"
      ],
      "metadata": {
        "id": "v9yWelWsfeNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx7OjfHTfheC",
        "outputId": "2b12ca74-c137-4719-af78-595536b73648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((383, 280, 280, 3), (383, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z586wXFu7ZgT"
      },
      "source": [
        "### (3) 모델1\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 구조 설계"
      ],
      "metadata": {
        "id": "NIvIO6RKa0mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "yW4LAyjZfCuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Functional API\n",
        "\n",
        "# 1번 세션 클리어\n",
        "clear_session()\n",
        "# 2번 레이어 엮기\n",
        "il = Input( shape=(280,280,3) )\n",
        "\n",
        "hl = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = GlobalAveragePooling2D()(hl)\n",
        "hl = Dropout(0,1)(hl)\n",
        "ol= Dense(2, activation='sigmoid')(hl)\n",
        "\n",
        "# 3번 모델의 시작과 끝 지정\n",
        "model1 = Model(il, ol)\n",
        "\n",
        "# 4번 컴파일\n",
        "model1.compile(loss=keras.losses.binary_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
        "# 요약\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ZmjvCBCifCyu",
        "outputId": "c8ce8ef1-3394-409f-84b9-ba74adb32717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-965e081d7b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1번 세션 클리어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# 2번 레이어 엮기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ],
      "metadata": {
        "id": "DHM91_bha3Kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHnFVZuKa42f"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=5,\n",
        "                   verbose=1,\n",
        "                   restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnrTSupKa42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ec49c9-1d78-45a4-c3e6-5c161fbb3963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "3/3 [==============================] - 52s 11s/step - loss: 1.1177 - accuracy: 0.5666 - val_loss: 0.7576 - val_accuracy: 0.5000\n",
            "Epoch 2/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.7194 - accuracy: 0.8329 - val_loss: 1.4195 - val_accuracy: 0.4792\n",
            "Epoch 3/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.4758 - accuracy: 0.8355 - val_loss: 1.7234 - val_accuracy: 0.4896\n",
            "Epoch 4/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.4001 - accuracy: 0.8486 - val_loss: 0.7230 - val_accuracy: 0.5208\n",
            "Epoch 5/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3177 - accuracy: 0.8799 - val_loss: 1.1773 - val_accuracy: 0.5000\n",
            "Epoch 6/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3003 - accuracy: 0.8930 - val_loss: 1.5013 - val_accuracy: 0.5000\n",
            "Epoch 7/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2632 - accuracy: 0.8956 - val_loss: 1.4709 - val_accuracy: 0.4688\n",
            "Epoch 8/10000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2612 - accuracy: 0.9086 - val_loss: 1.1187 - val_accuracy: 0.4688\n",
            "Epoch 9/10000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9269Restoring model weights from the end of the best epoch: 4.\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2285 - accuracy: 0.9269 - val_loss: 1.0799 - val_accuracy: 0.4375\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist = model1.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                 batch_size=128, epochs=10000, callbacks=[es], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val.shape, x_train.shape, y_val.shape, y_train.shape,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGtyiGXJjTom",
        "outputId": "39c0b71b-df3e-4200-a32a-db7920823de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((96, 280, 280, 3), (383, 280, 280, 3), (96, 2), (383, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(x_test)\n",
        "y_pred, y_test"
      ],
      "metadata": {
        "id": "EtJ8LtrLmQvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1_y_pred = np.where(y_pred>0.6,1,0)\n",
        "# model1_y_test = np.where(y_test>0.6,1,0)\n",
        "model1_y_test = y_test.argmax(axis=1)\n",
        "model1_y_pred = y_pred.argmax(axis=1)"
      ],
      "metadata": {
        "id": "RyfZ_ygPmY1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ],
      "metadata": {
        "id": "zage6-Z0a6DX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xkFFlFdbBZb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_y_pred[:5], model1_y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkA1VJ051QPi",
        "outputId": "9b8a1a54-ccc2-47b0-b948-0124136230c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_acc = accuracy_score(model1_y_test, model1_y_pred)\n",
        "print(f'테스트셋 정확도 : {model1_acc*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlV2JR6hmJW1",
        "outputId": "d6de2670-f5e6-4f97-be1a-535322880348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트셋 정확도 : 54.54545454545454%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-EQFVkCbBZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3759e1-eee4-4f03-8454-014de956a41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.69        60\n",
            "           1       1.00      0.10      0.18        61\n",
            "\n",
            "    accuracy                           0.55       121\n",
            "   macro avg       0.76      0.55      0.43       121\n",
            "weighted avg       0.76      0.55      0.43       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(model1_y_test, model1_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRoacK2mcLPb"
      },
      "source": [
        "### (4) 모델2\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 구조 설계"
      ],
      "metadata": {
        "id": "5WTwG8NFoLBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHu5gey1oLBR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "base_model2 = tf.keras.applications.EfficientNetV2B3(\n",
        "              include_top=False,\n",
        "              weights=\"imagenet\",\n",
        "              input_shape=None)\n",
        "\n",
        "new_output = GlobalAveragePooling2D()(base_model2.output)\n",
        "new_output = Dense(2, activation = 'sigmoid')(new_output)\n",
        "\n",
        "model2 = keras.models.Model(base_model2.inputs, new_output)\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "E48iQfq-q2hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'모델의 레이어 수 : {len(model2.layers)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0aZoRUwuxxY",
        "outputId": "3af7276d-829a-41fc-ccce-7f30c9b33bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 레이어 수 : 411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, layer in enumerate(model2.layers) :\n",
        "    if idx < 311 :\n",
        "        layer.trainable = False # 레이어의 학습을 안시킴. FROZEN.\n",
        "    else :\n",
        "        layer.trainable = True"
      ],
      "metadata": {
        "id": "X5cytAlHuoVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
        "             optimizer=keras.optimizers.Adam(learning_rate=0.001) )"
      ],
      "metadata": {
        "id": "fWvlrWPCu9GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ],
      "metadata": {
        "id": "DqTzgRTroLBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcVDXnpQoLBR"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=5,\n",
        "                   verbose=1,\n",
        "                   restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAhXnGmXoLBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc973ac-ead2-4695-a61b-9bb44c8e3936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 13s 11s/step - loss: 0.7511 - accuracy: 0.4360 - val_loss: 0.6912 - val_accuracy: 0.5729\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.7107 - accuracy: 0.5039 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7055 - accuracy: 0.5065 - val_loss: 0.7482 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7044 - accuracy: 0.4883 - val_loss: 0.7520 - val_accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7024 - accuracy: 0.5091 - val_loss: 0.7260 - val_accuracy: 0.5000\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5248Restoring model weights from the end of the best epoch: 1.\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5248 - val_loss: 0.7110 - val_accuracy: 0.5000\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist = model2.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                 batch_size=256, epochs=1000, callbacks=[es], verbose=1)\n",
        "\n",
        "#hist = model.fit(datagen.flow(train_x, train_y),\n",
        "                #  epochs=1000, validation_data=(valid_x, valid_y),\n",
        "                #  verbose=1, callbacks=[es, lr_reduction] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1cDMg-FuTO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ],
      "metadata": {
        "id": "qxZ0U7K1oLBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShruikbsoLBS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8MC8l07oLBS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7FVsFiCFSGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRqzBw8eccwj"
      },
      "source": [
        "### (5) 모델3\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 구조 설계"
      ],
      "metadata": {
        "id": "LtNd8u5RoNJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-Npn6WoNJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d017ee-779e-4d59-b5cf-12596acee0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 280, 280, 128)     3584      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 280, 280, 128)     147584    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 280, 280, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 140, 140, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 140, 140, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 140, 140, 256)     295168    \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 140, 140, 256)     590080    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 140, 140, 256)     590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 70, 70, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 70, 70, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 70, 70, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 70, 70, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 70, 70, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 35, 35, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 35, 35, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 627200)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 627200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 1254402   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,931,842\n",
            "Trainable params: 8,930,050\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "## Functional API\n",
        "\n",
        "# 1번 세션 클리어\n",
        "keras.backend.clear_session()\n",
        "# 2번 레이어 엮기\n",
        "il = Input( shape=(280,280,3) )\n",
        "\n",
        "hl = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Flatten()(hl)\n",
        "hl = Dropout(0,25)(hl)\n",
        "ol= Dense(2, activation='sigmoid')(hl)\n",
        "\n",
        "# 3번 모델의 시작과 끝 지정\n",
        "model3 = Model(il, ol)\n",
        "\n",
        "# 4번 컴파일\n",
        "model3.compile(loss=keras.losses.binary_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
        "# 요약\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ],
      "metadata": {
        "id": "4zgVkXLHoNJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTlUNbkhoNJo"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=8,\n",
        "                   verbose=1,\n",
        "                   restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4GYo0dboNJo"
      },
      "outputs": [],
      "source": [
        "hist = model3.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "                 batch_size=256, epochs=1000, callbacks=[es], verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ],
      "metadata": {
        "id": "uZV9zbsroNJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc9UmjZ0oNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP-p0_y9oNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxUpfhJ1xXle"
      },
      "source": [
        "## 4.모델링 II\n",
        "* **세부요구사항**\n",
        "    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n",
        "        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n",
        "            - ImageDataGenerator를 사용합니다.\n",
        "        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n",
        "            - VGG16(이미지넷)을 사용해 봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCRBdKPxCut"
      },
      "source": [
        "### (1) Data Augmentation\n",
        "- **세부요구사항**\n",
        "    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n",
        "    * Keras의 ImageDataGenerator를 이용\n",
        "        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
        "\n",
        "    * image generator를 이용하여 학습\n",
        "        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe6yjs8F7Zox"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYae9YFt8Q03"
      },
      "outputs": [],
      "source": [
        "img_size = 280 ## 사이즈 조정 가능\n",
        "\n",
        "train_path = dataset_path+'Car_Images_train/'\n",
        "valid_path = dataset_path+'Car_Images_val/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) ImageGenerator 생성\n",
        "* ImageDataGenerator 함수 사용\n",
        "    * 주요 옵션\n",
        "        * rotation_range: 무작위 회전을 적용할 각도 범위\n",
        "        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n",
        "        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n",
        "        * vertical_flip: 무작위 상하반전을 적용할지 여부\n",
        "        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"
      ],
      "metadata": {
        "id": "IP4jIyTGfXD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKPPSwYn7Zrj"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.3,\n",
        "                                   shear_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rotation_range=30,\n",
        "                                   zoom_range=0.3)\n",
        "\n",
        "# shear_range=이미지 굴절, zoom_range=확대축소, rotation_range=회전범위"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_datagen.fit(x_train)\n",
        "# valid_datagen.fit(x_val)"
      ],
      "metadata": {
        "id": "sykFcvvJJbbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/Datasets/Car_Images_train/gen\n",
        "!mkdir /content/drive/MyDrive/Datasets/Car_Images_val/gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXA1khsBKRGk",
        "outputId": "a98d5e06-02ec-4883-c723-00e9bc7061cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Datasets/Car_Images_val/gen’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ngwwrNMVY_",
        "outputId": "719ab1cc-cd35-4cec-85be-5826e4802b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.ImageDataGenerator at 0x7f7739d4f820>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 경로로 부터 이미지 불러 올 준비\n",
        "* .flow_from_directory 이용\n",
        "    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n",
        "    * 이미지를 불러올 때 target_size로 크기를 맞추고,\n",
        "    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"
      ],
      "metadata": {
        "id": "dKwSYYkufanb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bwvQ4hHSCwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e461cf-7d33-40f1-e963-1fb5ee981b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 388 images belonging to 2 classes.\n",
            "Found 96 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(directory=train_path, target_size=(280, 280), class_mode='binary', batch_size=32, shuffle=True)\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_path, target_size=(280, 280), class_mode='binary', batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RPCjU5f662"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 train_generator 이용.\n",
        "    - validation_data = valid_generator 지정\n",
        "    - Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 구조 설계"
      ],
      "metadata": {
        "id": "wVMLsXw6f663"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W7rqgH1f663"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(verbose=False):\n",
        "    input_tensor = Input(shape=(280, 280, 3))\n",
        "    pretrained_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    pretrained_output = pretrained_model.output\n",
        "\n",
        "    # customize Classifier layer\n",
        "    x = GlobalAveragePooling2D()(pretrained_output)\n",
        "    x = Dense(units=2, activation='relu')(x)\n",
        "    output = Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "4D29j2ZXXgqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "model_Xception = create_model(verbose=False)\n",
        "# 모델 compile\n",
        "model_Xception.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Yjvg6blCXmQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습\n",
        "    * EarlyStopping 설정하기\n",
        "    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"
      ],
      "metadata": {
        "id": "nw2_G7zdf663"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m5mRE9Nf663"
      },
      "outputs": [],
      "source": [
        "# es\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=5,\n",
        "                   verbose=1,\n",
        "                   restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCWzBSYqf663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f8c001-125b-49ec-d9df-ca7b81285153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 33s 3s/step - loss: 0.3645 - accuracy: 0.9639 - val_loss: 0.3651 - val_accuracy: 0.9375\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3542 - accuracy: 0.9897 - val_loss: 0.4042 - val_accuracy: 0.8958\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3657 - accuracy: 0.9794 - val_loss: 0.3855 - val_accuracy: 0.9271\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3596 - accuracy: 0.9871 - val_loss: 0.3620 - val_accuracy: 0.9583\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3550 - accuracy: 0.9845 - val_loss: 0.3918 - val_accuracy: 0.9375\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3475 - accuracy: 0.9974 - val_loss: 0.3735 - val_accuracy: 0.9583\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3703 - accuracy: 0.9820 - val_loss: 0.3884 - val_accuracy: 0.9896\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3916 - accuracy: 0.9665 - val_loss: 0.3825 - val_accuracy: 0.9688\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.9897Restoring model weights from the end of the best epoch: 4.\n",
            "13/13 [==============================] - 33s 3s/step - loss: 0.3569 - accuracy: 0.9897 - val_loss: 0.3642 - val_accuracy: 0.9792\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습(fit)\n",
        "train_hist = model_Xception.fit(train_generator, validation_data=valid_generator,\n",
        "                                batch_size=32, epochs=500, callbacks=[es], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'모델의 레이어 수 : {len(model_Xception.layers)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP7rXOhg8kDa",
        "outputId": "fdc853ac-9cd8-45f1-adac-350183af4421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 레이어 수 : 135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, layer in enumerate(model_Xception.layers) :\n",
        "  if idx < 100 :\n",
        "    layer.trainable = False\n",
        "  else :\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "S-gQQ3Pi8xPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Xception.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
        "                       optimizer=keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "metadata": {
        "id": "1MVLx3W19BUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hist = model_Xception.fit(train_generator, validation_data = valid_generator, batch_size=32, epochs=500, callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0_Umtb_9UDT",
        "outputId": "dacbbab0-bb17-408e-e511-3b87e863e0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 37s 2s/step - loss: 0.0485 - accuracy: 0.9923 - val_loss: 0.3704 - val_accuracy: 0.9792\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 27s 2s/step - loss: 0.0200 - accuracy: 0.9974 - val_loss: 0.0562 - val_accuracy: 0.9792\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0527 - accuracy: 0.9974 - val_loss: 0.9006 - val_accuracy: 0.9375\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.6511 - val_accuracy: 0.9375\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0166 - accuracy: 0.9974 - val_loss: 0.1327 - val_accuracy: 0.9792\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0471 - accuracy: 0.9923 - val_loss: 0.2263 - val_accuracy: 0.9896\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.0073 - val_accuracy: 0.9896\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 31s 2s/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.2424 - val_accuracy: 0.9583\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0879 - accuracy: 0.9794 - val_loss: 0.3306 - val_accuracy: 0.9375\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.2491 - val_accuracy: 0.9688\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0249 - accuracy: 0.9897 - val_loss: 0.2777 - val_accuracy: 0.9583\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 7.\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9688\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idxx, layer in enumerate(model_Xception.layers) :\n",
        "  if idxx < 110 :\n",
        "    layer.trainable = False\n",
        "  else :\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "-F_12wYo_kUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Acc=[0.9792, 0.9375]"
      ],
      "metadata": {
        "id": "lp-LciYsBoE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idxx, layer in enumerate(model_Xception.layers) :\n",
        "  if idxx < 130 :\n",
        "    layer.trainable = False\n",
        "  else :\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "Jqyj6gRCCep_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hist = model_Xception.fit(train_generator, validation_data = valid_generator, batch_size=32, epochs=500, callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dknEKnGS_tqB",
        "outputId": "ea7bb09a-cf6f-48f1-8825-0a98ebf17444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 30s 2s/step - loss: 0.3509 - accuracy: 0.9897 - val_loss: 0.3835 - val_accuracy: 0.9479\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 28s 2s/step - loss: 0.3552 - accuracy: 0.9845 - val_loss: 0.3513 - val_accuracy: 0.9792\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3516 - accuracy: 0.9948 - val_loss: 0.3504 - val_accuracy: 0.9688\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 33s 3s/step - loss: 0.3470 - accuracy: 0.9948 - val_loss: 0.3642 - val_accuracy: 0.9375\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3511 - accuracy: 0.9820 - val_loss: 0.3621 - val_accuracy: 0.9792\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3489 - accuracy: 0.9897 - val_loss: 0.3592 - val_accuracy: 0.9896\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 29s 2s/step - loss: 0.3464 - accuracy: 0.9974 - val_loss: 0.3566 - val_accuracy: 0.9583\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.9923Restoring model weights from the end of the best epoch: 3.\n",
            "13/13 [==============================] - 34s 3s/step - loss: 0.3522 - accuracy: 0.9923 - val_loss: 0.3676 - val_accuracy: 0.9583\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.9792, 0.9375"
      ],
      "metadata": {
        "id": "JEI5jy4-BsyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hist.validation_data"
      ],
      "metadata": {
        "id": "zCMYJpVoCBy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) 성능 평가\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ],
      "metadata": {
        "id": "BdKiY1uIf663"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjnvt0lf663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8980161c-b6c1-40e0-85af-c9e0c4ffe47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 223ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_Xception = model_Xception.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBl4Do0af663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00f31ed-3481-45db-8663-265d70984ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ],
      "source": [
        "y_pred_Xception.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "id": "2bbDAK5HjWRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_test = model_Xception.evaluate(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNKAGKvMiOPj",
        "outputId": "1979c936-2af4-4c1d-e87d-2b0dbef64ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUNng2BCiW7c",
        "outputId": "0a41bc7c-1ec0-4281-dc96-dbf106c1c4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.000000,  Test Accuracy : 0.000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1iv22vSxXle"
      },
      "source": [
        "### (2) Transfer Learning\n",
        "- **세부요구사항**\n",
        "    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다.\n",
        "        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n",
        "        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n",
        "    * VGG16 함수로 부터 base_model 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnS12YhDxXle"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) VGG16 불러와서 저장하기\n",
        "* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n",
        "* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"
      ],
      "metadata": {
        "id": "d3kyvCwIiAfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFf3IxbBGe9B"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(                 )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) VGG16과 연결한 구조 설계\n",
        "* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"
      ],
      "metadata": {
        "id": "D-JjBLZZiIxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4KhHQ8xXlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5heiDxxXlf"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "    - 데이터\n",
        "        * Image Generator를 연결하거나\n",
        "        * 기존 train, validation 셋을 이용해도 됩니다.\n",
        "        - Early Stopping을 반드시 사용하세요.\n",
        "        - 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtqQIS-HxXlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zg0L88Gwf4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) 성능 평가"
      ],
      "metadata": {
        "id": "BbhiWcS5i735"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik4AFzCQi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkkSsyMoi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuQMUJNxXSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}